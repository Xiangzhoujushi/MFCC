{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ideas from Fayem Hathak\n",
    "import numpy as np\n",
    "import scipy.io.wavfile \n",
    "import math\n",
    "import sys\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 2, 1, 2], dtype=int16)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_file = 'digits/1a.wav'\n",
    "(sample_rate,signal) = scipy.io.wavfile.read(first_file)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -45.92248052,  -27.85801638,  -18.94510424, ...,   48.56659859,\n",
       "          47.25829945,   55.27438165],\n",
       "       [ -53.36830903,  -39.31915389,  -21.72457235, ...,   33.38367164,\n",
       "          43.75532976,   48.86647684],\n",
       "       [-106.20967158,  -38.78208066,  -51.79248454, ...,   45.60205284,\n",
       "          50.17865609,   47.1292982 ],\n",
       "       ...,\n",
       "       [  -5.42218738,   -3.73613786,  -29.53261325, ...,   51.58408122,\n",
       "          57.34940589,   56.76356199],\n",
       "       [  -1.33646404,  -70.18774845,  -30.34573704, ...,   40.6958418 ,\n",
       "          45.28948928,   53.53474934],\n",
       "       [  38.15758681,   25.77228196, -124.74219861, ...,   21.01390259,\n",
       "          38.23031592,   52.34271163]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take 256 points FFT\n",
    "window_size = 256\n",
    "# shift = 20\n",
    "#pre_emphasis\n",
    "\n",
    "# pre-Emphasis\n",
    "alpha = 0.97 #preemphais coeff\n",
    "emphasized_signal = np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "# hamming = np.hamming(window_size)# hamming window \n",
    "# window_start = np.arange(0,new_signal.shape[0]-window_size,shift) # position of the start of the window\n",
    "# # windowing\n",
    "# frames = np.zeros([window_start.shape[-1],window_size],dtype = complex)\n",
    "# # frame\n",
    "# for i in np.arange(0,window_start.shape[-1]):\n",
    "#     start = window_start[i]\n",
    "#     X = np.fft.fft(new_signal[start:(start+window_size)]*hamming)\n",
    "#     frames[i,:] = X\n",
    "frame_size = 0.025\n",
    "frame_stride = 0.01\n",
    "\n",
    "\n",
    "frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "signal_length = len(emphasized_signal)# length of the signals\n",
    "frame_length = int(round(frame_length)) # round the frame_length\n",
    "frame_step = int(round(frame_step)) # get the step of the frame\n",
    "num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "pad_signal_length = num_frames * frame_step + frame_length\n",
    "z = np.zeros((pad_signal_length - signal_length))\n",
    "pad_signal = np.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).transpose()\n",
    "frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "\n",
    "frames *= np.hamming(frame_length)\n",
    "mag_frames = np.absolute(np.fft.rfft(frames, window_size))\n",
    "pow_frames = ((1.0 / window_size) * ((mag_frames) ** 2))\n",
    "# for i  in wi\n",
    "# we did not have duplicates\n",
    "high_mel_freq = 1125 * np.log(1 + (sample_rate/2) / 700)\n",
    "low_mel_freq = 0\n",
    "num_filter = 40 # number of filters\n",
    "mel_points = np.linspace(low_mel_freq, high_mel_freq, num_filter + 2)\n",
    "# in hertz\n",
    "hz_points = 700 * (math.e**(mel_points / 1127) - 1)\n",
    "bin = np.floor((window_size + 1) * hz_points / sample_rate)\n",
    "# filter banks\n",
    "fbank = np.zeros((num_filter, int(np.floor(window_size/2 + 1))))\n",
    "for m in range(1, num_filter+1):\n",
    "    f_m_left = int(bin[m - 1])    # left\n",
    "    f_m = int(bin[m])             # center\n",
    "    f_m_right = int(bin[m + 1])   # right\n",
    "    for k in range(f_m_left, f_m):\n",
    "        fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1]) #implement the filtering\n",
    "    for k in range(f_m, f_m_right):\n",
    "        fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m]) #implement the filtering\n",
    "# dot product between each bank with the power sum of the frame       \n",
    "filter_banks = np.dot(pow_frames, fbank.transpose()) # find the forier  \n",
    "filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "filter_banks = 20 * np.log(filter_banks) # take the logs\n",
    "# filter_banks\n",
    "num_ceps = 12 #number of ceps coefficients\n",
    "filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 12 features\n",
    "mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # keep ceps from 2 to 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 12)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221295.24926278047"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(mfcc[1,:],mfcc[1,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
